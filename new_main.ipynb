{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "835a6205-3114-44ee-a46b-6b4b175cb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io, math, os\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from nltk.corpus import cmudict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247aeaa4-b9a5-4b23-99cf-496ec868e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_srate(file_number):\n",
    "    directory = 'data/Data/F1/mat'\n",
    "    \n",
    "    # TODO: needs to ignore the .DS_Store file in a better way\n",
    "    file = sorted(os.listdir(directory))[file_number + 1]\n",
    "    \n",
    "    f = os.path.join(directory, file)\n",
    "    mat = scipy.io.loadmat(f)['usctimit_ema_f1_{:03}_{:03}'.format(file_number*5 + 1, file_number*5 + 5)]\n",
    "    \n",
    "    #returns the srate which is awkwardly stored here\n",
    "    return mat[0][1][1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d69d35d4-578f-4fec-a74f-a03f20ac5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can't put this in the utils file \n",
    "d = cmudict.dict()\n",
    "def nsyl(word):\n",
    "    try:\n",
    "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]]\n",
    "    except KeyError:\n",
    "        #if word not found in cmudict\n",
    "        return syllables(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d4bcd20-822c-4937-b9e5-e6a8efbb2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_list(position, dimension, file_number, starting_point, end_point):\n",
    "    values = []\n",
    "    if dimension == 'x':\n",
    "        dim = 0\n",
    "    elif dimension == 'y':\n",
    "        dim = 1 \n",
    "    elif dimension == 'z':\n",
    "        dim = 2\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    positions = ['UL', 'LL', 'JW', 'TB', 'TD', 'TT']\n",
    "    dataframes = [UL_df, LL_df, JW_df, TB_df, TD_df, TT_df]\n",
    "    index = positions.index(position)\n",
    "    \n",
    "    for i in range(end_point - starting_point):\n",
    "        coordinate = (dataframes[index][file_number][dim][starting_point + i])\n",
    "        if str(coordinate) != 'nan':\n",
    "            values.append(coordinate)\n",
    "            \n",
    "    return np.array(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d69d14e0-3aaa-4b74-ba92-967e859a6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['F1', 'F5', 'M1', 'M3']\n",
    "directory = 'data/Data/{}/mat'.format(subjects[0])\n",
    "counter = 1\n",
    "UL_df, LL_df, JW_df, TD_df, TB_df, TT_df = [], [], [], [], [], []\n",
    "\n",
    "for filename in sorted(os.listdir(directory)):\n",
    "    if filename.endswith('.mat'):\n",
    "        f = os.path.join(directory, filename)\n",
    "        mat = scipy.io.loadmat(f)\n",
    "        # takes the data that is stored at the key that precedes the data for each .mat file\n",
    "        data = mat['usctimit_ema_{}_{:03}_{:03}'.format(subjects[0].lower(), counter, counter + 4)]\n",
    "        counter += 5\n",
    "\n",
    "        # make dataframes of the six positions\n",
    "        UL_df.append(pd.DataFrame.from_dict(data[0][1][2]))\n",
    "        LL_df.append(pd.DataFrame.from_dict(data[0][2][2]))\n",
    "        JW_df.append(pd.DataFrame.from_dict(data[0][3][2]))\n",
    "        TD_df.append(pd.DataFrame.from_dict(data[0][4][2]))\n",
    "        TB_df.append(pd.DataFrame.from_dict(data[0][5][2]))\n",
    "        TT_df.append(pd.DataFrame.from_dict(data[0][6][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82ff066-e6f7-4d9c-acdd-2356b6cc9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = {}\n",
    "\n",
    "with open('timestamps.txt', 'r') as file:\n",
    "    timestamps = file.read().splitlines()\n",
    "    for word_number, line in enumerate(timestamps):\n",
    "        split_line = line.split(',')\n",
    "        sent_number = int(split_line[-1])\n",
    "        \n",
    "        # find start and end by multiplying the timestamps with the sampling rate\n",
    "        starting_point = math.floor(float(split_line[2]) * get_srate(int(split_line[0])))\n",
    "        end_point = math.ceil(float(split_line[3]) * get_srate(int(split_line[0])))\n",
    "        \n",
    "        # make dataframe for each word, so 3481 dataframes, for x and y seperately, and ingnoring z\n",
    "        # TODO: make this more efficient \n",
    "        data = {'word' : [split_line[1]],\n",
    "                'srate': [get_srate(int(split_line[0]))],\n",
    "                'sent' : [int(split_line[-1])],\n",
    "                'syl'  : [nsyl(split_line[1])],\n",
    "                'ULx'  : [get_pos_list('UL', 'x', int(split_line[0]), starting_point, end_point)],\n",
    "                'ULy'  : [get_pos_list('UL', 'y', int(split_line[0]), starting_point, end_point)],\n",
    "                'LLx'  : [get_pos_list('LL', 'x', int(split_line[0]), starting_point, end_point)],\n",
    "                'LLy'  : [get_pos_list('LL', 'y', int(split_line[0]), starting_point, end_point)],\n",
    "                'JWx'  : [get_pos_list('JW', 'x', int(split_line[0]), starting_point, end_point)],\n",
    "                'JWy'  : [get_pos_list('JW', 'y', int(split_line[0]), starting_point, end_point)],\n",
    "                'TDx'  : [get_pos_list('TD', 'x', int(split_line[0]), starting_point, end_point)],\n",
    "                'TDy'  : [get_pos_list('TD', 'y', int(split_line[0]), starting_point, end_point)],\n",
    "                'TBx'  : [get_pos_list('TB', 'x', int(split_line[0]), starting_point, end_point)],\n",
    "                'TBy'  : [get_pos_list('TB', 'y', int(split_line[0]), starting_point, end_point)],\n",
    "                'TTx'  : [get_pos_list('TT', 'x', int(split_line[0]), starting_point, end_point)],\n",
    "                'TTy'  : [get_pos_list('TT', 'y', int(split_line[0]), starting_point, end_point)]}\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        frames[word_number] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3cfc86f-ac6d-4b0d-8066-8c066fbafc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "syl1_words, syl2_words, syl3_words = {}, {}, {}\n",
    "syl4_words, syl5_words, syl6_words = {}, {}, {}\n",
    "\n",
    "syl_frames = [syl1_words, syl2_words, \n",
    "              syl3_words, syl4_words, \n",
    "              syl5_words, syl6_words]\n",
    "\n",
    "for i in range(1, len(syl_frames)+1):\n",
    "    for count, frame in enumerate(frames):\n",
    "        try:\n",
    "            if frames[frame].at[0, 'syl'][0] == i:\n",
    "                syl_frames[i-1][count] = frames[frame]\n",
    "        except:\n",
    "            if frames[frame].at[0, 'syl'] == i:\n",
    "                syl_frames[i-1][count] = frames[frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faa7a14c-4f11-4a1e-9214-c7393533a11c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can't extend empty axis 0 using modes other than 'constant' or 'empty'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jz/414l_qjs6s1bndtz3ppcy8cc0000gn/T/ipykernel_44758/3499652976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# checks if the pad length results in the correct target length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpad_length\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mpadded_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpad_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadded_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpad\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth_pair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    815\u001b[0m                     \u001b[0;34m\"can't extend empty axis {} using modes other than \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0;34m\"'constant' or 'empty'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: can't extend empty axis 0 using modes other than 'constant' or 'empty'"
     ]
    }
   ],
   "source": [
    "sensors = ['ULx', 'ULy', 'LLx', 'LLy', \n",
    "           'JWx', 'JWy', 'TDx', 'TDy', \n",
    "           'TBx', 'TBy', 'TTx', 'TTy']\n",
    "\n",
    "for frame in syl_frames:\n",
    "    # target length is the the word with the most samples in that syllable category\n",
    "    target_length = longest(frame)\n",
    "    for word in frame:\n",
    "        for sensor in sensors:\n",
    "            array = frame[word].at[0, sensor]\n",
    "            pad_length = int((target_length - len(array))/2)\n",
    "        \n",
    "            # checks if the pad length results in the correct target length\n",
    "            if (target_length - pad_length*2 - len(array)) == 0:\n",
    "                padded_array = np.pad(array, (pad_length, ), 'mean')\n",
    "                frame[word].at[0, sensor] = padded_array\n",
    "            \n",
    "            # if not, that means the total samples to be padded on both sides was odd, so it \n",
    "            # needs a little reshaping to have the correct length\n",
    "            else:\n",
    "                padded_array = np.pad(array, (pad_length+1, pad_length), 'mean')\n",
    "                frame[word].at[0, sensor] = padded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6492e6e9-cf03-4987-9a9e-9d5fc10d3e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a4771-3908-42aa-91ec-a952153ebfcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060bc25-adfc-4e37-a144-00841306ae3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68abae7d-b0d0-4aa7-8cb4-6fa1158aff33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e61d44-1ad6-4dd8-b849-e13f34893f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b592ba-328f-4b84-ba20-954ee6e77eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0897d5-08a7-4f43-b08b-740f766ac2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e12f30-71d7-445b-9e22-941f544e4e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
